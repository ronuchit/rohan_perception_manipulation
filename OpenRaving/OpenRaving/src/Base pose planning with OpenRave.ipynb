{
 "metadata": {
  "name": "Base pose planning with OpenRave"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "#Base pose planning with OpenRave\n\n**Disclaimer:**  \nThis is my first attempt at a tutorial using IPython notebooks. This is made all too complicated by the fact that I am using [OpenRave](http://openrave.org/docs/latest_stable/) that launches an external process with th viewer. To create this post I used [nbconvert](https://github.com/ipython/nbconvert) then imported the resulting html in Wordpress. The result is not very \"bloggy\" but it's kind of cool. I am open to suggestions for how to embed an IPython notebook into Wordpress. The same notebook can be viewed via [nbviewer](http://nbviewer.ipython.org/urls/raw.github.com/lorenzoriano/OpenRaving/master/Base%2520pose%2520planning%2520with%2520OpenRave.ipynb).\n\nA useful tool in robotics is to find base poses from where an object can be reached. This is not an easy problem and it is the subject of ongoing research from groups around the world. Below is my simple take at it: if you know up something about the the world's geometry (tables, objects, planes), then you can look for feasible solutions. Searching can be done in several different ways, but the approach I'm using here is as simple as effective: **sample**. This boils down to generating random solutions until one looks good. It seems crude but it does the job and it can be used as the starting point for more complex methods.\n\nFor those of you more into robotics, you will see an obvious parallel with [Rapidly-exploring Random Trees (RRTs)](http://msl.cs.uiuc.edu/rrt/), or in general stochastic motion planning.\n\nThis code assumes you have downloaded the helping routines from my [Github](https://github.com/lorenzoriano/OpenRaving) repository. You don't need the whole lot (which is not much at the time of writing, but hopefully it will grow larger), just the files [generate_reaching_poses](https://raw.github.com/lorenzoriano/OpenRaving/master/generate_reaching_poses.py) [navigation](https://raw.github.com/lorenzoriano/OpenRaving/master/navigation.py) and [utils](https://raw.github.com/lorenzoriano/OpenRaving/master/navigation.py).\n\nBelow is a [video](http://www.youtube.com/watch?v=o-sQ4nlPmVU) that shows the execution of exactly the same code as in this notebook, so you can see the effects without trying."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "from IPython.display import YouTubeVideo\nYouTubeVideo('o-sQ4nlPmVU', width=853, height=480)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": "\n            <iframe\n                width=\"853\"\n                height=\"480\"\n                src=\"http://www.youtube.com/embed/o-sQ4nlPmVU\"\n                frameborder=\"0\"\n                allowfullscreen\n            ></iframe>\n        ",
       "output_type": "pyout",
       "prompt_number": 4,
       "text": "<IPython.lib.display.YouTubeVideo at 0x306abd0>"
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "The first thing is to load the environment and the viewer. I am using a standard room provided by the OpenRave distribution."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "import openravepy; \nimport numpy as np\nenv = openravepy.Environment()\nenv.SetViewer('qtcoin')\nenv.Load('data/pr2test2.env.xml');",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Then load my code and select the object to grasp and the surface where to place it."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "%cd /home/pezzotto/Projects/OpenRaving #change this to the folder where you have placed your code.\nimport generate_reaching_poses\nimport utils\nrobot = env.GetRobots()[0]; manip = robot.SetActiveManipulator('rightarm')\nobj = env.GetKinBody('TibitsBox1')\ntable = env.GetKinBody('Table1')",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "/home/pezzotto/Projects/OpenRaving\n"
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "It's always a good idea to fold the arms before moving."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "utils.pr2_tuck_arm(robot)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Now come the first important part. First thing is to generate grasping positions for the gripper (this can be a long process). Then find a base position from where the gripper pose admits an IK solution, and which is collision free. Then plan a base trajectory to that position and executes it."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "pose, sol, torso = generate_reaching_poses.get_collision_free_grasping_pose(robot, obj, 300, use_general_grasps=False)\nimport navigation; planner = navigation.SimpleNavigationPlanning(robot)\nplanner.performNavigationPlanning(pose, execute=True)\nrobot.GetController().Reset()",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Once the robot has reached the base pose, lift the torso to the height found above. We are going to use motion planning to move the gripper in position, just to show some nice arm movements."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "robot.SetTransform(pose)\nrobot.SetDOFValues([torso], [robot.GetJointIndex('torso_lift_joint')],)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Here motion plannign kicks in. Give it some time."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "mplanner = openravepy.interfaces.BaseManipulation(robot)\nrobot.SetActiveDOFs(manip.GetArmIndices()); \nmplanner.MoveActiveJoints(sol)\nrobot.WaitForController(0);",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Ok, time to grab the object. We don't deal with real grasping here (the objects are just bounding boxes anyway)."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "robot.GetController().Reset()\nrobot.Grab(obj)\nutils.pr2_tuck_arm(robot)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "We are almost done. The final step is to find a free spot on a table, move there and place the object down. Finding a free spot on a table is very similar to finding a grasping position, but this time instead of checking grasps we check reachability of a random point on a surface. After having found the object we just teleport the robot, we already checked that motion planning works."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "pose, sol, torso = generate_reaching_poses.get_collision_free_surface_pose(robot, table, 100)\nrobot.SetTransform(pose)\nrobot.SetDOFValues(sol, robot.GetActiveManipulator().GetArmIndices())\nrobot.SetDOFValues([torso], [robot.GetJointIndex('torso_lift_joint')],)\nrobot.Release(obj)\nutils.pr2_tuck_arm(robot)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "That's it! quite crude but effective!"
    }
   ],
   "metadata": {}
  }
 ]
}